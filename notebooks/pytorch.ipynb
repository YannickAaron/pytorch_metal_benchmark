{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few potential stumbling blocks before beginning. PyTorch MPS requires MacOS 12.3 or later and an ARM Python installation.\n",
    "This can be checked by using the platform module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'macOS-12.3-arm64-arm-64bit'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.platform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next it can be installed:\n",
    "```python\n",
    "# MPS acceleration is available on MacOS 12.3+\n",
    "pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "```\n",
    "- torch: https://download.pytorch.org/whl/nightly/cpu/torch-1.13.0.dev20220701-cp39-none-macosx_11_0_arm64.whl\n",
    "\n",
    "- torchvision: https://download.pytorch.org/whl/nightly/cpu/torchvision-0.14.0.dev20220701-cp39-cp39-macosx_11_0_arm64.whl\n",
    "\n",
    "- torchaudio: https://download.pytorch.org/whl/nightly/cpu/torchaudio-0.14.0.dev20220603-cp39-cp39-macosx_11_0_arm64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we confirm that our torch installation has access to MPS/Metal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.has_mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is :: mps\n"
     ]
    }
   ],
   "source": [
    "CPU= False\n",
    "device = \"cpu\" if CPU else torch.device(\"mps\")\n",
    "print(\"Device is :: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args['dry_run']:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {'batch_size': 128, 'num_workers': 10, 'shuffle': True}\n",
    "test_kwargs = {'batch_size': 128, 'num_workers': 10, 'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'log_interval': 10, 'dry_run': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304453\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.268060\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.657003\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.373205\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.557102\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.366653\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.247815\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.187772\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.497210\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.285228\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.273993\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.218646\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.090166\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.124340\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.241153\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.071774\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.208764\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.299683\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.148412\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.142137\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.161658\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.132159\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.100068\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.162293\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.182341\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.156616\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.127034\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.138142\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.240737\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.150609\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.158129\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.093430\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.168967\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.183919\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.103966\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.106393\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.072137\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.103748\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.156362\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.168529\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.114532\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.042860\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.122350\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.063541\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.057869\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.032961\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.117560\n",
      "\n",
      "Test set: Average loss: 0.0617, Accuracy: 9803/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.128828\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.131653\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.086189\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.189375\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.081746\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.092215\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.056257\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.031847\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.042765\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.047912\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.104531\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.059997\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.118013\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.086543\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.060614\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.153102\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.153263\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.065965\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.026850\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.121197\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.059504\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.064160\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.044141\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.022427\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.022305\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.025496\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.006106\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.092756\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.105992\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.032062\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.065694\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.042604\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.067025\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.051856\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.022220\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.061093\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.132771\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.104314\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.153344\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.081062\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.024766\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.025309\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.049847\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.033466\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.036469\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.039539\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.093980\n",
      "\n",
      "Test set: Average loss: 0.0364, Accuracy: 9872/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.075282\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.054857\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.016878\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.059999\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.106197\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.050641\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.022519\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.018405\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.041234\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.019306\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.025619\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.082926\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.041433\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.035266\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.016348\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.036247\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.070979\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.043828\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.025562\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.060754\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.015269\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.042645\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.026750\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.053175\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.079495\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.065119\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.078006\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.048286\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.098430\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.013874\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.051841\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.059164\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.121948\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.028356\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.019218\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.066121\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.026836\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.016877\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.057603\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.049335\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.046852\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.044399\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.021906\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.004459\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.051304\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.073917\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.044892\n",
      "\n",
      "Test set: Average loss: 0.0310, Accuracy: 9894/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.084424\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.041896\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.028578\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.064836\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.041117\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.058276\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.056429\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.044232\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.019888\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.013769\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.017060\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.037404\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.042620\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.034813\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.031988\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.045800\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.065690\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.016142\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.084002\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.087539\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.009615\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.031104\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.011064\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.053286\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.105213\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.024409\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.045683\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.145897\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.051978\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.084881\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.032827\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.019475\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.061015\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.065134\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.030324\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.092234\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.017498\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.037196\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.042405\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.040607\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.025498\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.113107\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.035163\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.042326\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.031629\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.006867\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.011002\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.062040\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.008700\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.009683\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.070854\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.037152\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.040485\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.014397\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.027393\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.034338\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.222842\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.015186\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.068310\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.057570\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.034470\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.048932\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.038083\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.023732\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.042729\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.056585\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.016333\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.019121\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.053349\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.102673\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.016282\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.068279\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.013171\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.023099\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.057876\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.015474\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.040010\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.015954\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.047516\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.044200\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.033934\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.043212\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.041073\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.003607\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.039537\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.034718\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.018877\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.013271\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.002560\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.022068\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.051722\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.055577\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.006292\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.068902\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Time taken: 54.263205766677856\n"
     ]
    }
   ],
   "source": [
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "#set time\n",
    "start = time.time()\n",
    "for epoch in range(1, 5 + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()\n",
    "gpu_time = time.time() - start\n",
    "print(\"Time taken: {}\".format(gpu_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is :: cpu\n"
     ]
    }
   ],
   "source": [
    "CPU= True\n",
    "device = \"cpu\" if CPU else torch.device(\"mps\")\n",
    "print(\"Device is :: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.310045\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.560467\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.766729\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.588063\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.454216\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.402699\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.276324\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.285399\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.274607\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.207322\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.172833\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.175990\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.248890\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.258125\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.235406\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.180931\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.073137\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.247340\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.084198\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.112842\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.168954\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.191206\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.179214\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.055752\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.109282\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.141185\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.223176\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.069089\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.113669\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.058708\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.141774\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.099519\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.124054\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.201830\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.126627\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.086602\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.159791\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.138297\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.101588\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.098825\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.065705\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.189303\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.057572\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.074851\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.161409\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.053737\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.074621\n",
      "\n",
      "Test set: Average loss: 0.0497, Accuracy: 9835/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.105514\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.026634\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.101093\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.100461\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.164837\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.078577\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.047791\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.138338\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.132284\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.064693\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.069257\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.098788\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.054836\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.098383\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.109995\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.057661\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.105053\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.019835\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.033839\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.163218\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.071884\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.035859\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.173548\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.068371\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.062056\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.024292\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.063209\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.131942\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.052104\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.088054\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.051147\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.032307\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.041247\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.063710\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.053677\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.064995\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.120650\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.091960\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.052018\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.107112\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.123449\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.040629\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.065627\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.076514\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.061811\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.101119\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.067727\n",
      "\n",
      "Test set: Average loss: 0.0385, Accuracy: 9864/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.132083\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.018430\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.062058\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.030288\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.054514\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.096065\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.057365\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.071986\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.032096\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.064007\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.107645\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.037217\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.080430\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.060619\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.017132\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.058990\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.039874\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.070165\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.055173\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.023863\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.018674\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.016802\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.060043\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.006268\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.097734\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.021620\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.055630\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.052023\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.096299\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.020827\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.016503\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.073655\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.083776\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.060012\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.095707\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.035541\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.076805\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.060705\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.081018\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.031294\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.027876\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.038814\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.167716\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.112694\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.098892\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.035270\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.012132\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.008963\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.045519\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.011581\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.029205\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.040857\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.057229\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.030272\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.088306\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.047541\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.015129\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.042184\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.017039\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.061555\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.038713\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.036902\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.020582\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.014192\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.072691\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.093238\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.018115\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.145491\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.048882\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.055870\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.051804\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.005873\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.041402\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.024800\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.033356\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.050448\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.022017\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.035118\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.027741\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.041826\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.031882\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.096220\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.027737\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.049993\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.166011\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.062145\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.031961\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.012962\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.054390\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.038740\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.024878\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.009860\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.157242\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.047669\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.029513\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.041327\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.012731\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.011667\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.030984\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.045225\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.037725\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.041881\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.013139\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.078254\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.056545\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.013729\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.061614\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.028043\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.030310\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.057624\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.014940\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.042829\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.020356\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.072507\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.035226\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.040705\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.039740\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.022433\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.022744\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.034767\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.003932\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.052461\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.039622\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.051885\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.046311\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.009541\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.031068\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.020033\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.067455\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.057456\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.024542\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.012129\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.023075\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.048546\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.026587\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.009050\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.041307\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.055909\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.031420\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.055266\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.025035\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Time taken: 243.76270294189453\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "#set time\n",
    "start = time.time()\n",
    "for epoch in range(1, 5 + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()\n",
    "cpu_time = time.time() - start\n",
    "print(\"Time taken: {}\".format(cpu_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar graph with time taken\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['GPU', 'CPU'], [gpu_time, cpu_time], color=['green', 'red'])\n",
    "plt.xlabel('Device')\n",
    "plt.ylabel('Time taken (in sec)')\n",
    "plt.title('Time taken to train on CPU and GPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa2c575673d116eaf7dea0d4c2d9a4642c4bd6f8e70924e1eeb173b26e936e39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
