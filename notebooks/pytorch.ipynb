{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few potential stumbling blocks before beginning. PyTorch MPS requires MacOS 12.3 or later and an ARM Python installation.\n",
    "This can be checked by using the platform module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'macOS-12.3-arm64-arm-64bit'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.platform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next it can be installed:\n",
    "```python\n",
    "# MPS acceleration is available on MacOS 12.3+\n",
    "pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "```\n",
    "- torch: https://download.pytorch.org/whl/nightly/cpu/torch-1.13.0.dev20220701-cp39-none-macosx_11_0_arm64.whl\n",
    "\n",
    "- torchvision: https://download.pytorch.org/whl/nightly/cpu/torchvision-0.14.0.dev20220701-cp39-cp39-macosx_11_0_arm64.whl\n",
    "\n",
    "- torchaudio: https://download.pytorch.org/whl/nightly/cpu/torchaudio-0.14.0.dev20220603-cp39-cp39-macosx_11_0_arm64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we confirm that our torch installation has access to MPS/Metal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.has_mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.3.2-py3-none-any.whl (362 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from transformers) (1.23.0)\n",
      "Requirement already satisfied: filelock in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: requests in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1.tar.gz (220 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Using cached regex-2022.6.2-cp39-cp39-macosx_11_0_arm64.whl (281 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Using cached fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.0.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.13-py39-none-any.whl (132 kB)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: dill<0.3.6 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from datasets) (0.3.5.1)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.3-cp39-cp39-macosx_11_0_arm64.whl (10.5 MB)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Using cached pyarrow-8.0.0-cp39-cp39-macosx_11_0_arm64.whl (16.2 MB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.1-cp39-cp39-macosx_11_0_arm64.whl (552 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.7.2-cp39-cp39-macosx_11_0_arm64.whl (118 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (34 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\\"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/notebooks/pytorch.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/notebooks/pytorch.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset  \u001b[39m# pip install datasets\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/notebooks/pytorch.ipynb#ch0000004?line=2'>3</a>\u001b[0m \u001b[39m# load the first 1K rows of the TREC dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yannickaaron/Documents/GitHub/pytorch_metal_benchmark/notebooks/pytorch.ipynb#ch0000004?line=3'>4</a>\u001b[0m trec \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39m\u001b[39mtrec\u001b[39m\u001b[39m'\u001b[39m, split\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain[:1000]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset  # pip install datasets\n",
    "\n",
    "# load the first 1K rows of the TREC dataset\n",
    "trec = load_dataset('trec', split='train[:1000]')\n",
    "trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel  # pip install transformers\n",
    "\n",
    "# initialize BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# take the first 64 rows of the trec data\n",
    "text = trec['text'][:64]\n",
    "# tokenize text using the BERT tokenizer\n",
    "tokens = tokenizer(\n",
    "    text, max_length=512,\n",
    "    truncation=True, padding=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "model.to(device)\n",
    "tokens.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "config.num_labels = max(trec['label-coarse'])+1  # create 6 outputs\n",
    "model = BertForSequenceClassification(config).to(device)\n",
    "# remember to move to MPS with .to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate training mode of model\n",
    "model.train()\n",
    "\n",
    "# initialize adam optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "# begin training loop\n",
    "for batch in loader:\n",
    "  \t# note that we move everything to the MPS device\n",
    "    batch_mps = {\n",
    "        'input_ids': batch['input_ids'].to(device),\n",
    "        'attention_mask': batch['attention_mask'].to(device),\n",
    "        'labels': batch['labels'].to(device)\n",
    "    }\n",
    "    # initialize calculated gradients (from prev step)\n",
    "    optim.zero_grad()\n",
    "    # train model on batch and return outputs (incl. loss)\n",
    "    outputs = model(**batch_mps)\n",
    "    # extract loss\n",
    "    loss = outputs[0]\n",
    "    # calculate loss for every parameter that needs grad update\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optim.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa2c575673d116eaf7dea0d4c2d9a4642c4bd6f8e70924e1eeb173b26e936e39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
